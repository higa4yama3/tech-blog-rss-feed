<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="あっ、好きな記事をまとめたRSSフィードの配信"><meta name="author" content="higa4yama3"><meta name="robots" content="index, follow"><meta property="og:url" content="https://higa4yama3.github.io/tech-blog-rss-feed/"><meta property="og:title" content="ｼﾞｮｲｼﾞｮｲｼﾞｮｲのフィード｜RSS"><meta property="og:image" content="https://higa4yama3.github.io/tech-blog-rss-feed/images/og-image.png"><meta property="og:description" content="あっ、好きな記事をまとめたRSSフィードの配信"><meta property="og:type" content="website"><meta property="og:site_name" content="RSS"><meta property="og:locale" content="ja_JP"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://higa4yama3.github.io/tech-blog-rss-feed/"><meta property="twitter:url" content="https://higa4yama3.github.io/tech-blog-rss-feed/"><meta name="twitter:title" content="ｼﾞｮｲｼﾞｮｲｼﾞｮｲのフィード｜RSS"><meta 
name="twitter:description" content="あっ、好きな記事をまとめたRSSフィードの配信"><meta name="twitter:image" content="https://higa4yama3.github.io/tech-blog-rss-feed/images/og-image.png"><meta name="thumbnail" content="https://higa4yama3.github.io/tech-blog-rss-feed/images/og-image.png"><link rel="preload" href="../../styles/bundle.css?v=2" as="style"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;600;700;800&display=swap"><link rel="stylesheet" 
type="text/css" href="../../styles/bundle.css?v=2"><title>ｼﾞｮｲｼﾞｮｲｼﾞｮｲのフィード｜RSS</title></head><body><div class="site-wrapper"><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://joisino.hatenablog.com/">https://joisino.hatenablog.com/</a><p class="ui-blog-summary__description">ｼﾞｮｲｼﾞｮｲｼﾞｮｲｼﾞｮｲｼﾞｮｲ</p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" 
href="https://joisino.hatenablog.com/entry/llmsort"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/llmsort">LLMでソート</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">ソートはコンピュータサイエンスにおける古典的なタスクですが、これが最先端の LLM と結びつき、新たな研究の潮流が生まれています。 ソートは比較関数さえ定義すれば実行することができます。従来の比較関数は身長・金額・距離のように測定可能な数値の比較を前提としていましたが、この比較関数内で LLM 呼び出しを行うことで「どちらが好みか」「どちらが優れているか」「どちらがクエリに関連するか」といった主観的で曖昧な概念を比較でき、これらの概念に基づいたソートが可能になります。 Python では、二つのオブジェクト a と b を受け取り、a を前に持ってきたければ -1 を、b を前に持ってきたけれ…</div><div class="ui-feed-item__date" title="2026-02-09 08:28:09">21日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/zeh"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div 
class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/zeh">LLMの能力の「穴」</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">本稿では Even GPT-5.2 Can&#39;t Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs をもとに、最先端の LLM が未だにごく簡単な問題ですらミスすることを議論します。 具体例としては、11000 に含まれる 1 の数が偶数か奇数か聞くと、gpt-5.2-2025-12-11 は奇数と答えます。また、((((()))))) のカッコのバランスが取れているか聞くと、取れていると答えます。127×82 を計算させると、10314 と答えます（正解は 10414）。このことは以下のコマンドで確認できます…</div><div class="ui-feed-item__date" title="2026-01-26 08:20:35">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2025matome"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2025matome">2025 まとめ</a><div 
class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">2025 年も色々やりましたので活動を振り返ります。 目次 目次 研究 Solving the Cold Start Problem on One&#39;s Own as an End User via Preference Transfer（エンドユーザー自身が嗜好転移によりコールドスタート問題を自力で解決する） Influential Bandits: Pulling an Arm May Change the Environment（影響バンディット：アームを引くと環境が変わるかもしれない） Interestingness First Classifiers（面白さ優先分類器） Fast EX…</div><div class="ui-feed-item__date" title="2025-12-29 07:41:50">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/onedata"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/onedata">訓練データ1個だけでLLMの推論性能を倍にする</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
推論能力を高めるためには、LLM の事後訓練で使う訓練データは 1 つで十分かもしれません。本稿では訓練データを 1 つだけ使った強化学習についての研究 Reinforcement Learning for Reasoning in Large Language Models with One Training Example（単一の訓練例を用いた大規模言語モデルにおける推論のための強化学習, NeurIPS 2025）について解説します。 この研究の結論を直観的に述べると、厳選した数学の問題 1 問の解き方を LLM にひたすら考えさせ続けると高い推論能力が得られるということです。従来の訓練…</div><div class="ui-feed-item__date" title="2025-11-25 08:47:59">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/kimoi"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/kimoi">LLMのキモい算術</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
LLMは「226-68=」のようなプロンプトを与えると「158」と計算してくれますが、この計算は我々が想像するよりも奇妙な方法で行っていることを紹介します [Nikankin+ ICLR 2025]。 まずは前提条件を確認します。思考の連鎖は使わず、「226-68=」のようなプロンプトに対して「158」のように答えを直接出力する場合を考えます。 一例として Llama3-8B を考えます。Llama3 のトークナイザは 0 から 1000 までの数に 1 つのトークンを割り当てるので、「226-68=」を入力すると、次のトークン「158」が「0」「1」...「157」「158」「159」...…</div><div class="ui-feed-item__date" title="2025-10-27 08:35:49">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/heads"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/heads">LLM のアテンションと外挿</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
LLM の注意機構には色んな機能があることが分かっています。注意機構を分析することで、なぜ LLM は文脈内学習や思考の連鎖に成功し、ひいてはなぜ LLM が外挿に成功することがあるのかについての理解が得られます。本稿ではさまざまな種類の注意機構を観察することでこの問題をひも解きたいと思います。 目次 目次 基本的な考え方 文法ヘッド 注意の受け皿とレジスタトークン 逐次ヘッドと検索ヘッド 帰納ヘッド 関数ベクトル 反復ヘッド まとめ 基本的な考え方 LLM の多くは注意機構と多層パーセプトロン (MLP) を交互に積み上げたアーキテクチャを持ちます。各層は複数の注意機構をもち、それぞれの機構…</div><div class="ui-feed-item__date" title="2025-09-29 08:26:04">5ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/eureka"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/eureka">面白さ優先分類器</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
既存の機械学習モデルの多くは予測精度を最大化することを目指しますが、本稿では面白さを優先する分類器を紹介します。 目次 目次 面白さを優先するとは 問題設定 手法 実験結果 おわりに 面白さを優先するとは 例えば、ユーザーのプロフィールから、そのユーザーが成人しているかどうかを分類する問題を考えましょう。 ユーザーのプロフィールに年齢の特徴量 age があれば、年齢が 18 歳以上かどうか (age &gt;= 18) という分類ルールで精度 100% を達成できます。SNS では嘘の年齢を書いている可能性もありますが、大抵の人はおおむね正しい年齢を報告しているはずなので、精度 99% 程度は達成で…</div><div class="ui-feed-item__date" title="2025-08-28 08:22:50">6ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/mislead"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/mislead">人間を騙してサボるAIたち</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
AI の能力が上がるにつれて、人間が AI を監督するのが難しくなってきています。本稿では、Anthropic などのグループが ICLR 2025 で発表した Language Models Learn to Mislead Humans via RLHF（言語モデルは RLHF を通じて人間を誤解させることを学ぶ）をベースに、この問題について議論します。 この論文では、LLM が解けないほど難しいタスク、例えば難しいプログラミングのタスクに直面したとき、「分かりません」と言ったり、一目で分かるような間違ったコードを出力すると BAD ボタンを押されてしまうので、あえて出力を複雑にしたりデバ…</div><div class="ui-feed-item__date" title="2025-06-23 08:17:34">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/anna"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/anna">アンナ・カレーニナの法則と真理に収束していくモデルたち</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
幸せな家族はどれもみな同じようにみえるが、不幸な家族にはそれぞれの不幸の形がある。 — 『アンナ・カレーニナ』 アンナ・カレーニナの法則 (Anna Karenina principle) とは、成功の状態は一つしかないが、失敗の状態は無数にありうるという、トルストイの小説『アンナ・カレーニナ』の有名な冒頭に由来する法則です。機械学習においては、ヤミニ・バンサルらの研究 [Bansal+ NeurIPS 2021] をはじめとする、モデルの表現（埋め込み）についての以下の観察が知られています。 機械学習におけるアンナ・カレーニナの法則：性能の良いモデルはどれもみな同じような表現をもっているが、…</div><div class="ui-feed-item__date" title="2025-05-20 08:26:20">9ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/physics"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/physics">言語モデルの物理学</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
言語モデルの物理学 (Physics of Language Models) とは、FAIR (Meta) の Zeyuan Allen-Zhu が提唱した、言語モデルの研究を進めるためのコンセプトです。ざっくり言うと、「あのモデルはこう」とか「そのモデルはこのモデルよりもこう」というような博物学的な知識を深めるのではなく、17世紀にケプラーやニュートンが物理学において行ったような原理に基づいた研究を進め、「言語モデルはなぜこのような振る舞いをするのか」という問いに答えられるようになるべきという考え方です。 言語モデルの物理学の特徴は大きく2つあります。 第一は、ウェブから収集したコーパスを使…</div><div class="ui-feed-item__date" title="2025-03-24 08:19:05">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/theory"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/theory">絶対に分かる機械学習理論</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
私が機械学習を学び始めたとき、訓練データとテストデータは異なるのだから、訓練データ上で損失を下げたとしても、テストデータでの性能が必ずしも保証されるとは限らないのではないかと感じ、理解に苦労しました。 本稿では、かつての自分を含め、統計と機械学習の初心者に向けて、なぜテストデータでも性能が理論的に保証されるのかを丁寧に解説します。 本稿の最後では、この議論を深層学習の理論に応用し、最先端の研究にまで一気に繋げます。期待値や分散などの統計学の基礎知識だけからここまで発展的な内容にまでたどり着くというのが本稿の目的です。ぜひ最後までお付き合いください。 目次 目次 期待値への集中 マルコフの不等式…</div><div class="ui-feed-item__date" title="2025-03-17 08:23:21">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/superai"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/superai">人間には認知できない情報を活用するAIたち</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
正月休みに Twitter（現 X）を眺めていると面白いポストを見かけました。 これまで人類は真理とは単純なものであると考えて、 や のような単純な真理を追いかけてきたわけですが、このようなものは実は真理のうちのごく一部であり、人間には理解できないほど複雑な真理もあるのではないかという考え方です。 ❌「AIが人間より質的量的に賢くなったら人間には理解しきれなくなる」⭕️「この世界はもともと人間には理解しきれない構造になっていて、AIはそこを扱えるようになる」みたいな世界観を持っていたほうが良さそうな気がする— すきえんてぃあ@書け (@cicada3301_kig) 2024年12月31日 似…</div><div class="ui-feed-item__date" title="2025-01-15 08:13:57">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024matome"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024matome">2024 まとめ</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
2024 年も色々やりましたので活動を振り返ります。 目次 目次 本 グラフニューラルネットワーク ★ 深層ニューラルネットワークの高速化 ★ 論文 Training-free Graph Neural Networks and the Power of Labels as Features Overhead-free User-side Recommender Systems ブログ モデルパラメータの算術 ★ 大学で読んだ情報科学関連の教科書 ★ トランスフォーマーは RNN である ★ サービス開発 Readable Amax 講演 クリック率を最大化しない推薦システム ★ Introd…</div><div class="ui-feed-item__date" title="2024-12-30 08:28:51">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/negation"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/negation">否定文を理解できないAIたち</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
BERT や GPT の登場により、テキストを扱うモデルは大きく発展しましたが、否定というごくありふれた操作を扱うのが依然難しいです。 本稿では、その理由と、部分的な解決策を紹介します。 目次 目次 否定文を理解できないAIたち 否定文を理解できずに困ること なぜ否定文をうまく扱えないのか なぜたまに成功するのか 対処法 ファインチューニング プロンプトの工夫 否定文を意識した訓練 文書数を増やす クエリとキーを拡張する おわりに 否定文を理解できないAIたち BERT (tohoku-nlp/bert-base-japanese-v3) で A =「私はお寿司が好きです。」 B =「私の好き…</div><div class="ui-feed-item__date" title="2024-12-18 08:27:09">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/11/21/173951"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/11/21/173951">Amazonの推薦をいい感じにするブラウザ拡張Amaxをリリースしました</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
Amazonの推薦をいい感じにするブラウザ拡張Amaxというブラウザ拡張をリリースしました。会員登録など必要なく、もちろん無料で、ブラウザ拡張をインストールしていつも通り Amazon を使うだけでいい感じになります。手軽なのでぜひ使ってみてくださいね。 chromewebstore.google.com 私の専門は推薦システムで、特にユーザーサイドの推薦システムに力を入れて研究をしています（プロフィール）。このブラウザ拡張にはユーザーサイドの推薦システムの研究成果がふんだんに詰め込まれています。 本稿では、ブラウザ拡張の紹介のほか、開発の裏側やもとになった技術について詳しく説明します。 目次…</div><div class="ui-feed-item__date" title="2024-11-21 08:39:51">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/09/30/173416"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/09/30/173416">トランスフォーマーは RNN である</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
拙著『深層ニューラルネットワークの高速化』が重版して第 2 刷となりました。皆さまありがとうございます！ 深層ニューラルネットワークの高速化 (ML Systems)作者:佐藤 竜馬技術評論社Amazon もはや恒例、重版に感謝して書き下ろし専門記事をお届けします。 本稿では、SNS などでもたびたび話題になるトランスフォーマーは RNN であるという話をします。本稿では単に形式的に包含性を指摘するだけでなく、トランスフォーマーと RNN はどの程度似ているのかや、そこから導かれる応用上の意味についても詳しくご紹介します。 本稿は『深層ニューラルネットワークの高速化』の第 6.3 節と第 7.…</div><div class="ui-feed-item__date" title="2024-09-30 08:34:16">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/08/27/170428"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/08/27/170428">『深層ニューラルネットワークの高速化』を上梓しました。</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
深層ニューラルネットワークの高速化 ML Systems作者:佐藤 竜馬技術評論社Amazon 技術評論社より『深層ニューラルネットワークの高速化（ML Systems）』を上梓しました。 （※ ML Systems というのは本書が一作目となる技術評論社の新しいシリーズで、今後も機械学習 × エンジニアリングの本が刊行予定のようです。乞うご期待！） 深層ニューラルネットワークは画像、言語、音声などさまざまな領域で活躍を見せていますが、標準的なモデルサイズは年々増加の一途をたどっており、使用するのが難しくなっています。本書は深層ニューラルネットワークを高速化することでこの問題に対処する方法を紹…</div><div class="ui-feed-item__date" title="2024-08-27 08:04:28">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/08/07/164440"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/08/07/164440">深層学習で部分空間を扱うときは射影行列を考えるとよい</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
拙著『グラフニューラルネットワーク』が重版して第 5 刷となりました。皆さまありがとうございます！ 【重版速報🎉🎉🎉🎉】 機械学習プロフェッショナルシリーズの重版が決まりました😆ご愛読ありがとうございます‼️松井孝太・熊谷亘『転移学習』【4刷】 https://t.co/Qic24KAwxD佐藤竜馬『グラフニューラルネットワーク』【5刷】 https://t.co/Peqn1ZQavo pic.twitter.com/VBkNp2Uwjj— 講談社サイエンティフィク🖋️📔 (@kspub_kodansha) 2024年8月1日 グラフニューラルネットワーク (機械学習プロフェッショナルシリーズ…</div><div class="ui-feed-item__date" title="2024-08-07 07:44:40">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/05/15/170023"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/05/15/170023">GNN の最新動向 (ICLR 2024)</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
拙著『グラフニューラルネットワーク』が重版して第 3 刷となりました。皆さまありがとうございます！ 拡散モデルと最適輸送でもやりましたが、漫画家さんやイラストレーターさんが重版したときに重版感謝の描き下ろしイラストを投稿しているのを見ていいなと思ったので、僕も専門書が重版したときに重版感謝の書き下ろし専門記事を投稿します。 本稿では、ICLR 2024（5/7 - 5/11 @ウィーン）で発表されたグラフニューラルネットワーク (GNN) 関連の研究動向を紹介します。 ICLR 2024 で発表された GNN 関連の論文は全部で 170 本です。凄まじい量ですね。ICLR 2024 では全て合…</div><div class="ui-feed-item__date" title="2024-05-15 08:00:23">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/04/25/172451"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/04/25/172451">『グラフニューラルネットワーク』を上梓しました</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
グラフニューラルネットワーク (機械学習プロフェッショナルシリーズ)作者:佐藤 竜馬講談社Amazon 講談社より『グラフニューラルネットワーク（機械学習プロフェッショナルシリーズ）』を上梓しました。 グラフニューラルネットワークはグラフデータのためのニューラルネットワークです。化合物やソーシャルネットワークのようなグラフデータの解析に使うことができます。また後で述べるように、テキストも画像もグラフなのでテキストや画像の分析にも使えますし、それらを組み合わせたマルチモーダルなデータにも適用できます。要は何にでも使うことができます。この汎用性がグラフニューラルネットワークの大きな強みです。 本稿…</div><div class="ui-feed-item__date" title="2024-04-25 08:24:51">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/04/10/174525"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/04/10/174525">松井・熊谷『転移学習』の感想</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
講談社サイエンティフィク様より『転移学習』をご恵贈いただきました。一通り読み終えたので感想を書きます。 転移学習 (機械学習プロフェッショナルシリーズ)作者:松井 孝太,熊谷 亘講談社Amazon 全 414 ページとかなりの重厚感。しかも決して引き伸ばした跡がなく、むしろ原液のような濃さを感じる中身です。原理に基づいて本質的な事項が解説されており、しっかり読むととても力のつく一冊だと思いました。 転移学習の難しさを直視する 本書の大きな特徴は転移学習の難しさを誤魔化さずに正面から取り扱っている点です。 転移学習とは、元ドメインのデータ と目標ドメインのデータ が与えられたときに、目標ドメイン…</div><div class="ui-feed-item__date" title="2024-04-10 08:45:25">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/03/27/181258"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/03/27/181258">大学で読んだ情報科学関連の教科書</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
先日、博士（情報学）になりました。学部と大学院をあわせた 9 年間で読んだ情報科学関連の教科書・専門書を思い出を振り返りつつここにまとめます。私は授業はあまり聞かずに独学するタイプだったので、ここに挙げた書籍を通読すれば、大学に通わなくてもおおよそ情報学博士ほどの知識は身につくものと思われます。ただし、特に大学院で重要となる論文を読み書きすることについては本稿には含めておりません。それらについては論文読みの日課についてや論文の書き方などを参考にしてください。 joisino.hatenablog.com 凡例：（半端）とは、数章だけ読んだ場合か、最後まで読んだものの理解が浅く、今となっては薄ぼ…</div><div class="ui-feed-item__date" title="2024-03-27 09:12:58">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/03/08/174412"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/03/08/174412">拡散モデルと最適輸送</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
『最適輸送の理論とアルゴリズム』が重版して第 5 刷となりました。皆さまありがとうございます！ 漫画家さんやイラストレーターさんが重版したときに重版感謝の描き下ろしイラストを投稿しているのを見ていいなと思ったので、僕も専門書が重版したときに重版感謝の書き下ろし専門記事を投稿します。 本稿では、最近話題の拡散モデルと最適輸送の関係を直観的に解説します。 拡散モデルは画像の生成によく用いられる生成モデルです。モデルはノイズ入りの画像を受け取り、ノイズを除去することを目指します。生成時には、完全なノイズ画像からはじめて、モデルによりノイズを除去することと、微小なノイズを加えることを繰り返して洗練させ…</div><div class="ui-feed-item__date" title="2024-03-08 08:44:12">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2024/01/09/174517"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2024/01/09/174517">モデルパラメータの算術</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
深層モデルのパラメータを一列に並べてベクトルにします。このベクトルは大規模なモデルであれば何十億次元にもなります。一見、意味のない数値の羅列のようですが、このベクトルはベクトルとして深い意味があることが分かってきています。例えば、 と を異なるパラメータベクトルとすると、 や をパラメータとして持つモデルはちゃんと機能します。本稿では、このようなモデルパラメータの算術を用いた手法とその背後にある理論について解説します。 追記： 拙著『深層ニューラルネットワークの高速化』にて本稿の内容を大幅に増補しました。本稿に興味を持った方はこちらも参照いただけると嬉しいです。 深層ニューラルネットワークの高…</div><div class="ui-feed-item__date" title="2024-01-09 08:45:17">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2023/12/27/175940"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2023/12/27/175940">『Human-in-the-Loop 機械学習』</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
共立出版さまより『Human-in-the-Loop 機械学習』をご恵贈いただきました。一通り読み終えたので感想を共有します。 映り込みが激しくて写真を撮るのが難しいことで有名な表紙 本書は機械学習モデルを訓練するためのデータを人間がどのように用意するかという問題を扱っています。本書の前半では能動学習というラベル付けデータの選び方の技法が、本書の後半では人間が付けたラベルの管理方法やラベル付けのための適切なインターフェースが紹介されています。 機械学習におけるデータをいかに作るかということは私自身とても注目している領域です。『Active Learning from the Web（能動学習を…</div><div class="ui-feed-item__date" title="2023-12-27 08:59:40">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2023/12/21/164617"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2023/12/21/164617">2023 まとめ</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
2023 も色々やりました。 ↓去年 joisino.hatenablog.com 研究 今年はあまり論文を出版できませんでした。去年 10 本出版しましたとか言って調子に乗っていたのに……。優しい内臓先生の「私は過去の自分と比較するのが好きです。高確率で勝てるので。」という言葉が好きなのですが、私は負けました。悔しい。調子良かった年だけ貼るのも良くないのでちゃんと今年も貼ります（偉い）。 本の執筆 去年一年ずっと執筆していた『最適輸送の理論とアルゴリズム』が無事出版されました。買っていただいた皆様ありがとうございます。まだ買っていない方も、まだこの本を読む人生の楽しみがあるということでおめで…</div><div class="ui-feed-item__date" title="2023-12-21 07:46:17">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2023/10/29/164650"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2023/10/29/164650">君たちはどう研究するか</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
IBIS 2023 のパネルディスカッション「君たちはどう研究するか」にて研究の取り組み方についてお話しました。この記事はそこでお話した内容を編集したものです。 🔍研究テーマの決め方について 📆 研究プロジェクトの進め方 😵‍💫 研究がうまくいかないときの対処法 📝 論文の書き方 おわりに 🔍研究テーマの決め方について 僕は研究テーマ選びはあまり重要ではないと考えています。どういうテーマにめぐり合うかは運なので、そこで思いつめても仕方がありません。なので、僕は自分から積極的にテーマを探しにいくということはしていません。それよりも、テーマを決めたあとの掘り下げ方という自分でコントロールする部分に…</div><div class="ui-feed-item__date" title="2023-10-29 07:46:50">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2023/04/10/170519"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2023/04/10/170519">論文読みの日課について</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
かれこれ三年以上ほぼ毎朝論文を読んでいます。 ほぼ毎朝、というのは本当にほぼ毎朝です。この三年のうち読まなかった日はワクチンの副反応でダウンしている日など、あわせて 10 ~ 20 日ほどでしかありません。この日課だけでも 1000 本以上は論文を読んだことになります。 論文読みの日課についての知見が溜まってきたのでこの記事で共有します。 主な想定読者は研究者と学生の皆さんですが、それ以外の論文読みに興味のある皆さんにも有用な情報が詰まっているはずです。 日課の流れ Readable について 🧐 論文の選び方 自分の研究内容と直接関係あるものを読む（特におすすめ） 完全にランダムに選ぶ 被引…</div><div class="ui-feed-item__date" title="2023-04-10 08:05:19">3年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2022/12/20/173709"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2022/12/20/173709">2022 まとめ</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
2022年にはいろんなことがありました。 研究 今年もたくさん研究をして論文を書きました。主著だけでも10本出版しました。記念のスクリーンショットです。 出しすぎで草 これについての想定アンチコメントは「研究は量より質」です。 ごもっともです。すみませんでした。 本の執筆 この1年はずっと『最適輸送の理論とアルゴリズム』という本を書いていました。ベストセラー記念のスクリーンショットです。 たくさん予約いただきありがとうございました。 本屋大賞への投票もよろしくお願いします。 （追記：本屋大賞受賞の対象外だそうです。すみませんでした。） 本を書くのは初めての経験でした。僕は論文執筆のスピードは速…</div><div class="ui-feed-item__date" title="2022-12-20 08:37:09">3年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://joisino.hatenablog.com/entry/2022/09/20/172453"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://joisino.hatenablog.com/entry/2022/09/20/172453">論文の書き方</a><div class="ui-feed-item__blog-title">ｼﾞｮｲｼﾞｮｲｼﾞｮｲ</div><div class="ui-feed-item__summary">
どのようにして論文を書いているかを尋ねられることが最近よくあります。場当たり的に回答することが多かったのですが、このことについて改めてしっかり考えて公開することにしました。 ここで扱う内容は、科学者とはこうあるべき、という理想論ではなく、等身大の大学院生がいかにして論文を捻りだすかという実践的な方法論です。科学者の規範に照らすと適切ではない内容もあるかと思いますがご容赦ください。その代わり、現役の大学院生にとってはただちに活用できる内容になったと思います。 以下では時系列に沿って各段階の方法について述べていきます。 アイデアを考える まずは論文のアイデアを収集します。僕は普段からネタ帳にアイデ…</div><div class="ui-feed-item__date" title="2022-09-20 08:24:53">3年前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-section-footer__layout ui-layout-flex"><p class="ui-text-note">higa4</p></div></div></footer></div></body></html>